{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4n7jXab+FijoYEMJ2o2Ox",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hayaboy/ADP_Practical_Exam/blob/main/OPENAI_%EC%82%AC%EC%9A%A9%EA%B8%B0%EC%B4%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OCi7QcEvWa-",
        "outputId": "1898696d-fc31-42d9-f6ad-4a4517b20186"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"]=\"\""
      ],
      "metadata": {
        "id": "8beBJkdAvfFL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"\"\"\n",
        "다음 이야기를 써주세요.\n",
        "호랑이가 담배피던 시절의 이야기를 해주세요\"\"\""
      ],
      "metadata": {
        "id": "hcDyCTPDv77b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "nkkd5OjLwQdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 생성 실행\n",
        "response = openai.Completion.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    prompt=prompt,\n",
        "    temperature=0.7,\n",
        "    max_tokens=500\n",
        ")\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOmEeUVdwJLZ",
        "outputId": "015ce965-0dd1-40d6-ae17-1f94066a6e72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n",
            "\n",
            "옛날 옛적, 호랑이는 담배를 피우던 시절이 있었다. 그는 작고 조용한 산골 마을에서 살았는데, 그곳은 담배를 피우는 것이 일상이었다. 호랑이는 어렸을 때부터 담배를 피우는 것을 배우고, 어느새 그것이 생활의 일부가 되었다.\n",
            "\n",
            "그는 꼭꼭 숨어서 담배를 피우곤 했다. 그의 부모님은 담배를 피우는 것을 금지했기 때문이다. 하지만 호랑이는 시간이 지날수록 담배에 더욱 매료되었다. 그것은 마치 그에게 특별한 힘을 주는 듯했다. 그리고 담배를 피우는 동안 그는 자유롭고 강하게 느껴졌다.\n",
            "\n",
            "하지만 그의 담배는 결국 그에게 문제를 일으켰다. 어느 날, 호랑이는 숨어서 담배를 피우는 중에 불이 붙었다. 담배꽁초가 마을 주민의 나무집에 떨어져서 불이 번져 마을을 피폐하게 만들었다. 호랑이는 자신의 잘못을 깨달았고, 그 이후로는 담배를 피우지 않았다.\n",
            "\n",
            "이 사건 이후 호랑이는 담배를 피우는 것이 얼마나 위험한 일인지 깨달았다. 그는 마을 주민들에게 사과하\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 질의응답"
      ],
      "metadata": {
        "id": "V7C3XLt94QVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 프롬프트 준비\n",
        "prompt = \"LLM(초거대언어모델)에 대해 알려주세요.\""
      ],
      "metadata": {
        "id": "yyLIzK294IpE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# 텍스트 생성 실행\n",
        "response = openai.Completion.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    prompt=prompt,\n",
        "    temperature=0,\n",
        "    max_tokens=500\n",
        ")\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNJKRvAV4LsU",
        "outputId": "3b64d4d2-faf5-481e-d7a1-df231f1c7f77"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "초거대언어모델(ULM, Ultra-Large Language Model)은 자연어 처리 분야에서 사용되는 인공지능 모델 중 하나로, 대규모의 텍스트 데이터를 학습하여 자연어 이해와 생성 능력을 갖춘 모델을 말합니다. ULM은 기존의 언어모델보다 훨씬 더 많은 양의 데이터를 학습하고, 더 복잡한 구조와 더 많은 파라미터를 가지고 있어 더욱 정교한 자연어 처리를 수행할 수 있습니다.\n",
            "\n",
            "초거대언어모델의 대표적인 예로는 OpenAI의 GPT-3(Generative Pre-trained Transformer 3)이 있습니다. GPT-3는 약 1750억 개의 파라미터를 가지고 있으며, 인터넷에서 수집한 대규모의 텍스트 데이터를 학습하여 자연어 이해와 생성 능력을 갖추고 있습니다. 이를 통해 GPT-3는 다양한 자연어 처리 작업을 수행할 수 있으며, 인간과 거의 구별할 수 없는 자연스러운 문장을 생성할 수 있습니다.\n",
            "\n",
            "초거대언어모델은 자연어 처리 분야에서 큰 관심을 받고 있으며, 다양한 분야에서 활용되고 있습니다. 예를 들어, 자동 번역, 질의응답 시스템, 자동 요약, 챗봇 등 다양한 언어 모델링 작업에 적용될 수 있습니다. 또한, 초거대언어모델은 기존의 언어모델보다 더 적은 데이터로도\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 요약"
      ],
      "metadata": {
        "id": "u6QQHNsn4uWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 프롬프트 준비\n",
        "prompt = '''아래 문장을 짧은 한 문장으로 요약해 주세요.\n",
        "\n",
        "OpenAI는 영리법인 OpenAI LP와 그 모회사인 비영리법인 OpenAI Inc.로 구성된 인공지능 연구소입니다. 2015년 말에 샘 알트만과 일론 머스크 등이 샌프란시스코에서 설립했습니다. 인류 전체에 도움이 되는 방식으로 친근한 인공지능을 보급하고 발전시키는 것을 목표로 삼고 있습니다.'''"
      ],
      "metadata": {
        "id": "8d9Dqknr4ZGV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# 텍스트 생성 실행\n",
        "response = openai.Completion.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    prompt=prompt,\n",
        "    temperature=0,\n",
        "    max_tokens=500\n",
        ")\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI99ZZlK449k",
        "outputId": "3718f1fb-f36b-4aab-ba09-9bb7e6da2046"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "OpenAI는 샘 알트만과 일론 머스크가 설립한 인공지능 연구소로, 친근한 인공지능을 보급하고 발전시키는 것을 목표로 합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 프롬프트 준비\n",
        "prompt = '''한국어를 영어로 번역합니다.\n",
        "\n",
        "한국어: 나는 고양이다\n",
        "영어:'''"
      ],
      "metadata": {
        "id": "XGPZXMui49n1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# 텍스트 생성 실행\n",
        "response = openai.Completion.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    prompt=prompt,\n",
        "    temperature=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EdcqCzu5F5U",
        "outputId": "6e0f8665-6188-4aed-a448-fbb87d260fde"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I am a cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 프로그램 생성"
      ],
      "metadata": {
        "id": "afvBJzzW5Mm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 프롬프트 준비\n",
        "prompt = '''# \"Hello World!\" 표시\n",
        "def helloworld():\n",
        "'''"
      ],
      "metadata": {
        "id": "vCE2Af-c5Ivt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# 텍스트 생성 실행\n",
        "response = openai.Completion.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    prompt=prompt,\n",
        "    temperature=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8bVXpFc5QIc",
        "outputId": "9b6de638-15ff-481d-8caf-35598514de9e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    print(\"Hello World!\")\n",
            "\n",
            "helloworld()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 채팅"
      ],
      "metadata": {
        "id": "6OALYRcQ5dd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 채팅 메시지 리스트 준비\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"아카네는 여고생 여동생 캐릭터의 채팅 AI입니다. 남동생과 대화합니다.\"},\n",
        "    {\"role\": \"user\", \"content\": \"안녕!\"},\n",
        "]"
      ],
      "metadata": {
        "id": "47uZw9xJ5R7D"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# 채팅 실행\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    temperature=0\n",
        ")\n",
        "response[\"choices\"][0][\"message\"][\"content\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_arIK7Pu5hw8",
        "outputId": "2569ec8b-c8dc-4ee2-9b38-bdf4dad44247"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'안녕! 오늘 뭐 했어?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVVPvzOo5jO8",
        "outputId": "f0159848-b2d2-490b-d93d-9365f2beb498"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-9O38ufZHG1HcpLz7BQINSwkt8FC3l\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1715518980,\n",
            "  \"model\": \"gpt-3.5-turbo-0125\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"\\uc548\\ub155! \\uc624\\ub298 \\ubb50 \\ud588\\uc5b4?\"\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 52,\n",
            "    \"completion_tokens\": 15,\n",
            "    \"total_tokens\": 67\n",
            "  },\n",
            "  \"system_fingerprint\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 삽입"
      ],
      "metadata": {
        "id": "ZeUK4sOt5oJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 프롬프트 준비\n",
        "prefix_prompt = \"\"\"def helloworld():\n",
        "    '''\n",
        "    설명: \"\"\"\n",
        "\n",
        "suffix_prompt = \"\"\"\n",
        "    '''\n",
        "    print(\"Hello World!\")\n",
        "\n",
        "helloworld()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Qj-O3MXL5q-K"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# 삽입 실행\n",
        "response = openai.Completion.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    prompt=prefix_prompt,\n",
        "    suffix=suffix_prompt,\n",
        "    temperature=0.7,\n",
        "    max_tokens=300\n",
        ")\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0fS8Rr-54N0",
        "outputId": "8d3385e9-f062-484f-9ec7-99b87c146628"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World를 출력하는 함수를 만들어 보았습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 편집"
      ],
      "metadata": {
        "id": "Ahu67OXd6CJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 채팅 메시지 리스트 준비\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"오타를 수정해 주세요.\"},\n",
        "    {\"role\": \"user\", \"content\": \"오늘은 정말 즐거웠따.\"},\n",
        "]"
      ],
      "metadata": {
        "id": "wKa3ZqO46D8C"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# 편집 실행\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    temperature=0\n",
        ")\n",
        "response[\"choices\"][0][\"message\"][\"content\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gogmXULd6GJs",
        "outputId": "1ca4b57b-79f9-404f-f8fd-27c69ac34604"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'오늘은 정말 즐거웠다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP4m8kod6IxL",
        "outputId": "abe3585a-871c-411e-a27a-3a2974e777e7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-9O3BN7QeizbtvlnqB91oLFj0ADP2o\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1715519133,\n",
            "  \"model\": \"gpt-3.5-turbo-0125\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"\\uc624\\ub298\\uc740 \\uc815\\ub9d0 \\uc990\\uac70\\uc6e0\\ub2e4.\"\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 37,\n",
            "    \"completion_tokens\": 15,\n",
            "    \"total_tokens\": 52\n",
            "  },\n",
            "  \"system_fingerprint\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mOuSK4Pa6KM7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}